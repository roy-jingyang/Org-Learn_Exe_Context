import sys

import pandas as pd

import ordinor.constants as const
from ordinor.io import read_csv

from _search_algo_utils import evaluate_ec, print_log_stats, print_collated_results

if __name__ == '__main__':
    fn_log = sys.argv[1]
    variant = sys.argv[2]
    T0 = int(sys.argv[3])
    # Load data
    log = read_csv(fn_log)

    params = ['variant', 'T0', 'comment']
    for param, v in zip(params, sys.argv[2:]):
        print('{}={}'.format(param, v), end=', ')
    comment='T0-{}'.format(
        T0
    )
    print()

    # Filter out cases without selected case-attribute information
    cases_rm = set()
    SEL_ATTRS = [
        'case:LoanGoal', 'case:ApplicationType',
        # TODO: include numeric attribtes
    ]
    for case, events in log.groupby(const.CASE_ID):
        for attr in SEL_ATTRS:
            if events[attr].isna().all():
                cases_rm.add(case)
                break
    log = log[~log[const.CASE_ID].isin(cases_rm)]

    # Derive new columns based on the original ones
    # CT-related: N/A
    # AT-related: N/A
    # TT-related
    log.loc[:, 'year'] = log[const.TIMESTAMP].dt.year
    log.loc[:, 'month'] = log[const.TIMESTAMP].dt.month
    log.loc[:, 'weekday'] = log[const.TIMESTAMP].dt.day_name()

    # Derive execution contexts
    # 'NULL' denotes null type

    rl = log[[const.RESOURCE]]
    ct_cands = ['NULL'] + SEL_ATTRS
    at_cands = ['NULL', const.ACTIVITY]
    tt_cands = ['NULL', 'month', 'weekday']

    # Evaluate execution contexts (generated by search)
    from ordinor.execution_context import GreedySearchMiner, GreedyODTMiner, SASearchMiner
    spec = {
        'type_def_attrs': {
            'case:LoanGoal': {'attr_type': 'categorical', 'attr_dim': 'CT'},
            'case:ApplicationType': {'attr_type': 'categorical', 'attr_dim': 'CT'},
            # TODO: include numerical attributes
            const.ACTIVITY: {'attr_type': 'categorical', 'attr_dim': 'AT'},
            'month': {'attr_type': 'categorical', 'attr_dim': 'TT'},
            'weekday': {'attr_type': 'categorical', 'attr_dim': 'TT'},
        }
    }

    # Print log stats
    print_log_stats(log, spec)

    log.to_csv(fn_log + '.filtered.csv')
    exit()

    if variant == 'greedy':
        miner = GreedySearchMiner(
            log, spec, 
            init_method='zero',
            print_steps=True, trace_history=True,
            size_neighborhood=10, max_iter=T0
        )
        rl = miner.derive_resource_log(log)
    elif variant == 'odt':
        miner = GreedyODTMiner(
            log, spec, 
            print_steps=True, trace_history=True,
            size_neighborhood=10, max_iter=T0
        )
        rl = miner.derive_resource_log(log)
    elif variant == 'sa':
        miner = SASearchMiner(
            log, spec, 
            init_method='zero',
            print_steps=True, trace_history=True,
            size_neighborhood=50, T0=T0, Tmin=3e-4, alpha=0.95, 
            restart_interval=50
        )
        rl = miner.derive_resource_log(log)
    elif variant == 'baseline':
        rl = []
        for i, row in log.iterrows():
            rl.append({
                const.RESOURCE: row[const.RESOURCE],
                const.CASE_TYPE: '-'.join(
                    str(row[x]) for x in ['case:LoanGoal', 'case:ApplicationType']
                ),
                const.ACTIVITY_TYPE: '-'.join(
                    str(row[x]) for x in [const.ACTIVITY]
                ),
                const.TIME_TYPE: '-'.join(
                    str(row[x]) for x in ['month', 'weekday']
                )
            })
        rl = pd.DataFrame(rl)
    else:
        exit('Invalid parameter: {}'.format(variant))

    dis, imp = evaluate_ec(rl)

    print(miner.type_dict)
    
    ts_now = pd.Timestamp.now()
    fn_miner = '{}-bpic17_{}_{}.miner'.format(
        miner.__class__.__name__,
        ts_now.strftime('%Y%m%d-%H%M%S.%f'),
        comment
    )
    print('Output miner to {}'.format(fn_miner))
    with open(fn_miner, 'wb') as fout:
        miner.to_file(fout)

    print_collated_results(miner, dis, imp)
                
