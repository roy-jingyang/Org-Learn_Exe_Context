import sys

import pandas as pd

import ordinor.constants as const
from ordinor.io import read_csv, read_disco_csv
from ordinor.execution_context.rule_based import dispersal, impurity
from ordinor.org_model_miner.resource_features import direct_count
from ordinor.org_model_miner.group_discovery import ahc
from ordinor.org_model_miner.group_profiling import overall_score
from ordinor.conformance import fitness, precision

def evaluate_ec(rl):
    COLS = [const.CASE_TYPE, const.ACTIVITY_TYPE, const.TIME_TYPE]
    # m_event_co : pandas.Series
    #     An array indexed by event ids, recording labels of the execution
    #     contexts to which the events belong to.
    mat_event_co = rl[COLS]
    for col in COLS:
        codes, _ = pd.factorize(mat_event_co[col])
        mat_event_co.loc[:, col] = codes.astype(str)
    mat_event_co.loc[:, '_co'] = mat_event_co[COLS].agg('-'.join, axis=1)
    mat_event_co.loc[:, '_co'], _ = pd.factorize(mat_event_co['_co'])
    m_event_co = mat_event_co['_co']
    # m_co_t : pandas.DataFrame
    #     An array indexed by execution context ids, recording labels of
    #     the case types, activity types, and time types of execution
    #     contexts, i.e., the column number is 3.
    m_co_t = mat_event_co.drop_duplicates(subset='_co')
    m_co_t = m_co_t.set_index('_co')
    m_co_t = m_co_t.astype(int)
    # m_event_r : pandas.Series
    #     An array indexed by event ids, recording ids of the resources who
    #     originated the events.
    m_event_r = rl[const.RESOURCE]
    imp = impurity(m_event_co, m_event_r)
    dis = dispersal(m_co_t, m_event_co, m_event_r)
    return dis, imp

def disc_eval_om(rl, ct=None, at=None, tt=None, n_groups=2):
    if ct is not None and at is not None and tt is not None:
        print(f'CT={ct}, AT={at}, TT={tt}')
        # construct resource log by manually specifying attributes as types
        rl.loc[:, const.CASE_TYPE] = log[ct] if ct != 'NULL' else ct
        rl.loc[:, const.ACTIVITY_TYPE] = log[at] if at != 'NULL' else at
        rl.loc[:, const.TIME_TYPE] = log[tt] if tt != 'NULL' else tt
    
    # discover organizational model
    profiles = direct_count(rl, scale='normalize')
    rgs = ahc(profiles, n_groups=n_groups)
    om = overall_score(rgs, rl, auto_search=True)
    
    # evaluate organizational model
    fit = fitness(rl, om)
    prec = precision(rl, om)
    
    print('Fitness:\t{:.3f}'.format(fit))
    print('Precision:\t{:.3f}'.format(prec))
    
    return om, fit, prec
    
if __name__ == '__main__':
    print('*' * 20)
    # MODE = 'learn' / 'load'
    MODE = sys.argv[1]
    print('MODE: {}'.format(MODE))
    MAX_HEIGHT = int(sys.argv[2])
    print('MAX_HEIGHT: {}'.format(MAX_HEIGHT))
    if len(sys.argv) > 3:
        fn_miner = sys.argv[3]
        print('fn_miner: {}'.format(fn_miner))
    print('*' * 20)

    # Load data
    log = read_disco_csv('./input/bpic2015_old.preprocessed.csv')

    # Filter out events with meaningless resource labels or without any resource label
    #log = log[~log[const.RESOURCE].isin(['test', 'TEST'])]

    # Filter out cases without selected case-attribute information
    cases_rm = set()
    SEL_ATTRS = [
        'ct:permit_type'
    ]
    for case, events in log.groupby(const.CASE_ID):
        for attr in SEL_ATTRS:
            if events[attr].isna().all():
                cases_rm.add(case)
                break
    log = log[~log[const.CASE_ID].isin(cases_rm)]

    # Derive new columns based on the original ones
    # CT-related: N/A
    # AT-related: N/A
    # TT-related: N/A

    # Derive execution contexts
    # 'NULL' denotes null type

    '''
    rl = log[[const.RESOURCE]]
    ct_cands = ['NULL'] + SEL_ATTRS
    at_cands = ['NULL', const.ACTIVITY]
    tt_cands = ['NULL', 'year', 'month', 'weekday']

    # Evaluate execution contexts (generated by manually specifying types)
    results = []
    for (ct, at, tt) in product(ct_cands, at_cands, tt_cands):
        print(f'CT={ct}, AT={at}, TT={tt}')
        rl.loc[:, const.CASE_TYPE] = log[ct] if ct != 'NULL' else ct
        rl.loc[:, const.ACTIVITY_TYPE] = log[at] if at != 'NULL' else at
        rl.loc[:, const.TIME_TYPE] = log[tt] if tt != 'NULL' else tt
        dis, imp = evaluate_ec(rl)
        print('Dispersal:\t{:.3f}'.format(dis))
        print('Impurity:\t{:.3f}'.format(imp))
        results.append({'CT': ct, 'AT': at, 'TT': tt, 'dispersal': dis, 'impurity': imp})
    '''

    # Evaluate execution contexts (generated by ODT learning)
    from ordinor.execution_context import ODTMiner
    spec = {
        'type_def_attrs': {
            'ct:permit_type': {'attr_type': 'categorical', 'attr_dim': 'CT'},
            'at:phase': {'attr_type': 'categorical', 'attr_dim': 'AT'},
            'tt:weekday': {'attr_type': 'categorical', 'attr_dim': 'TT'},
            'tt:ampm': {'attr_type': 'categorical', 'attr_dim': 'TT'},
        }
    }
                
    if MODE == 'learn':
        miner = ODTMiner(log, spec, max_height=MAX_HEIGHT, trace_history=True)
    else:
        from ordinor.execution_context.base import BaseMiner
        with open(fn_miner, 'rb') as fin:
            miner = BaseMiner.from_file(fin)
    rl = miner.derive_resource_log(log)
    dis, imp = evaluate_ec(rl)
    print('Dispersal:\t{:.6f}'.format(dis))
    print('Impurity:\t{:.6f}'.format(imp))

    ts_now = pd.Timestamp.now()
    fn_miner = 'ODTMiner-bpic15_h{}_{}.miner'.format(
        MAX_HEIGHT, 
        ts_now.strftime('%Y%m%d-%H%M%S')
    )
    if MODE == 'learn':
        print('Output miner to {}'.format(fn_miner))
        with open(fn_miner, 'wb') as fout:
            miner.to_file(fout)
    exit(1)

    # Discover and evaluate organizational models
    om, fit, prec = disc_eval_om(rl, n_groups=list(range(2, 25)))

    # Show organizational model
    for rg_id, rg in om.find_all_groups():
        print(rg)
        print('\t{}'.format(', '.join(sorted(om.find_group_members(rg_id)))))
        print('\t{}'.format(om.find_group_execution_contexts(rg_id)))
